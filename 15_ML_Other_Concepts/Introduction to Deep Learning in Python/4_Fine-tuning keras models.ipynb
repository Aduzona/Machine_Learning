{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning keras models\n",
    "\n",
    "Learn how to optimize your deep learning models in Keras. Start by learning how to validate your models, then understand the concept of model capacity, and finally, experiment with wider and deeper networks.\n",
    "\n",
    "## Understanding model optimization\n",
    "\n",
    "Stochastic Gradient Descent, sometimes abbreviated to SGD.This optimizer uses a fixed learning rate. Learning rates around 0.01 are common. But you can specify the learning rate you need with lr argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosing optimization problems\n",
    "\n",
    "The following could prevent a model from showing an improved loss in its first few epochs?\n",
    "\n",
    "* Learning rate too low.\n",
    "* Learning rate too high.\n",
    "* Poor choice of activation function\n",
    "All the options listed could prevent a model from showing an improved loss in its first few epochs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"titanic_all_numeric.csv\")\n",
    "predictors=df.drop(['survived'],axis=1).astype(np.float32).to_numpy()\n",
    "target=df.survived.astype(np.float32).to_numpy()\n",
    "# Convert the target to categorical: target\n",
    "target=to_categorical(df.survived)\n",
    "n_cols=predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing optimization parameters\n",
    "\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Import SGD from keras.optimizers.\n",
    "* Create a list of learning rates to try optimizing with called lr_to_test. The learning rates in it should be .000001, 0.01, and 1.\n",
    "* Using a for loop to iterate over lr_to_test:\n",
    "    * Use the get_new_model() function to build a new, unoptimized model.\n",
    "    * Create an optimizer called my_optimizer using the SGD() constructor with keyword argument lr=lr.\n",
    "* Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use 'categorical_crossentropy' for the loss parameter.\n",
    "* Fit your model using the predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aduzo\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 2s 3ms/step - loss: 2.5913\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5710\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.5507\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.5307\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 2.5109\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4913\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.4719\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.4526\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.4336\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 2.4147\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 1s 3ms/step - loss: 3.7663\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8672\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6668\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6306\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6423\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6202\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6135\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6028\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5853\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6040\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 1s 4ms/step - loss: 209.1981\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6712\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6734\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6719\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6698\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6703\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6701\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6699\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6696\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.6626\n"
     ]
    }
   ],
   "source": [
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer,loss='categorical_crossentropy' )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors,target,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "Using Validation data to test for model peformance.\n",
    "\n",
    "**Early Stopping**\n",
    "\n",
    "Helps to stop training when validation score is not improving.\n",
    "patience argument is how many epochs the model can go without improving before we stop training. 2 or 3 are reasonable values for patience. \n",
    "\n",
    "inside the fit function, callbacks takes a list.\n",
    "\n",
    "by default 10 epochs\n",
    "nb_epoch = max epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model accuracy on validation dataset\n",
    "\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as model. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Compile your model using 'adam' as the optimizer and 'categorical_crossentropy' for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument metrics=['accuracy'] in model.compile().\n",
    "* Fit the model using the predictors and target. Create a validation split of 30% (or 0.3). This will be reported in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 3s 58ms/step - loss: 0.9346 - accuracy: 0.6116 - val_loss: 0.6410 - val_accuracy: 0.6007\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6443 - accuracy: 0.6693 - val_loss: 0.6636 - val_accuracy: 0.6903\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6110 - accuracy: 0.6758 - val_loss: 0.5143 - val_accuracy: 0.7687\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6432 - accuracy: 0.6709 - val_loss: 0.5415 - val_accuracy: 0.7463\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6143 - accuracy: 0.6950 - val_loss: 0.4909 - val_accuracy: 0.7575\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7095 - val_loss: 0.4889 - val_accuracy: 0.7687\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5623 - accuracy: 0.7416 - val_loss: 0.5371 - val_accuracy: 0.7724\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5914 - accuracy: 0.7255 - val_loss: 0.5319 - val_accuracy: 0.7836\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5723 - accuracy: 0.7352 - val_loss: 0.6181 - val_accuracy: 0.7127\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5614 - accuracy: 0.7319 - val_loss: 0.5819 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors,target,validation_split=0.3,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping: Optimizing the optimization\n",
    "\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for epochs in your call to .fit(), as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Import EarlyStopping from keras.callbacks.\n",
    "* Compile the model, once again using 'adam' as the optimizer, 'categorical_crossentropy' as the loss function, and metrics=['accuracy'] to see the accuracy at each epoch.\n",
    "* Create an EarlyStopping object called early_stopping_monitor. Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2.\n",
    "* Fit the model using the predictors and target. Specify the number of epochs to be 30 and use a validation split of 0.3. In addition, pass [early_stopping_monitor] to the callbacks parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - 3s 51ms/step - loss: 0.8444 - accuracy: 0.6228 - val_loss: 0.8947 - val_accuracy: 0.5448\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.7766 - accuracy: 0.6822 - val_loss: 0.5368 - val_accuracy: 0.7201\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6129 - accuracy: 0.6709 - val_loss: 0.5046 - val_accuracy: 0.7612\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6193 - accuracy: 0.6806 - val_loss: 0.5304 - val_accuracy: 0.7537\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.7264 - accuracy: 0.6645 - val_loss: 0.5021 - val_accuracy: 0.7612\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5824 - accuracy: 0.6918 - val_loss: 0.5357 - val_accuracy: 0.7425\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.6504 - accuracy: 0.6677 - val_loss: 0.5921 - val_accuracy: 0.6940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d623856048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,epochs=30,validation_split=0.3,callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with wider networks\n",
    "\n",
    "Now you know everything you need to begin experimenting with different models!\n",
    "\n",
    "A model called model_1 has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument verbose=False in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictors.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(predictors.shape[1],)\n",
    "# Create the new model: model_2\n",
    "model_1 = Sequential()\n",
    " \n",
    "# Add the first and second layers\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    " \n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    " \n",
    "# Compile model_2\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Create model_2 to replicate model_1, but use 100 nodes instead of 10 for the first two Dense layers you add with the 'relu' activation. Use 2 nodes for the Dense output layer with 'softmax' as the activation.\n",
    "* Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "* Hit 'Submit Answer' to fit both the models and visualize which one gives better results! Notice the keyword argument verbose=False in model.fit(): This prints out fewer updates, since you'll be evaluating the models graphically instead of through text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The blue model is model_2, the red is model_1. model_2 had a lower loss value, so it is the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding layers to a network\n",
    "\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called model_1 as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 50)                550       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 652\n",
      "Trainable params: 652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(predictors.shape[1],)\n",
    "# Create the new model: model_2\n",
    "model_1 = Sequential()\n",
    " \n",
    "# Add the first and second layers\n",
    "model_1.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    " \n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    " \n",
    "# Compile model_2\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Specify a model called model_2 that is like model_1, but which has 3 hidden layers of 50 units instead of only 1 hidden layer.\n",
    "    * Use input_shape to specify the input shape in the first hidden layer.\n",
    "    * Use 'relu' activation for the 3 hidden layers and 'softmax' for the output layer, which should have 2 units.\n",
    "* Compile model_2 as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy'].\n",
    "Run to fit both the models and visualize which one gives better results! For both models, you should look for the best val_loss and val_acc, which won't be the last epoch for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 =  Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The blue model is Model_2 and the red is model_1. The model with the lower loss value is the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking about model capacity\n",
    "\n",
    "\"Model capacity\" or \"network capacity\" is closely related to the terms overfitting and underfitting.\n",
    "\n",
    "**Overfitting**\n",
    "\n",
    "![Model Capacity](4_0_Model_Capacity.png)\n",
    "\n",
    "Model capacity is a model's ability to capture predictive patterns in your data. So, the more capacity a model, the further to the right we will be on this graph. If you had a network, and you increased the number of nodes or neurons in a hidden layer, that would increase model capacity. And if you add layers, that increases capacity. Said another way, making larger layers or increasing the number of layers moves you further to the right of this graph.\n",
    "\n",
    "**Workflow for optimizing model capacity**\n",
    "\n",
    "![Sequential](4_1_Model_Capacity_Optimization.png)\n",
    "\n",
    "Let's walk through that process once. Here, I've started a model that has one hidden layer and $100$ units. That's a relatively simple, or low capacity, model. I get a mean squared error of $5.4$. Since I started with a simple model, I now try increasing capacity. I could increase the number of layers or use more hidden nodes. \n",
    "* I'll start by using more nodes in the one hidden layer. That improved the model, so I'll keep increasing capacity.\n",
    "* This time I'll switch to using 2 hidden layers. Each layer has 250 nodes. That improved the error more. \n",
    "* So, I try 3 layers, continuing to add capacity as long as it helps,This hurt the score. So, the model with 2 layers and 250 nodes is about perfect. I'll try another model that reduces capacity slightly from the last model I built.\n",
    "* That is 3 hidden layers with 200 nodes each. That seems the best model yet. So I'll stick with that. Should you change capacity by adding layers or by adding nodes to an existing layer? There isn't a universal answer to that. You can experiment. But you should generally be thinking about whether you are trying to increase or decrease capacity, ideally honing in on the right capacity by looking at validation scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with model structures\n",
    "\n",
    "You've just run an experiment where you compared two networks that were identical except that the 2nd network had an extra hidden layer. You see that this 2nd network (the deeper network) had better performance. Given that, Increasing the number of units in each hidden layer would be a good next step to try achieving even better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepping up to images\n",
    "\n",
    "Using MNIST dataset. Your model will predict which image was written.\n",
    "\n",
    "### Building your own digit recognition model\n",
    "\n",
    "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\n",
    "\n",
    "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from Keras are also pre-imported.\n",
    "\n",
    "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\n",
    "\n",
    "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a [blog post](https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws) by Dan that explains how to do this - check it out after completing this exercise! It is a great next step as you continue your deep learning journey.\n",
    "\n",
    "Ready to take your deep learning to the next level? Check out [Advanced Deep Learning with Keras](https://app.datacamp.com/learn/courses/advanced-deep-learning-with-keras) to see how the Keras functional API lets you build domain knowledge to solve new types of problems. Once you know how to use the functional API, take a look at [Image Processing with Keras in Python](https://app.datacamp.com/learn/courses/image-processing-with-keras-in-python) to learn image-specific applications of Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 785)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"mnist.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.12</th>\n",
       "      <th>0.13</th>\n",
       "      <th>0.14</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.16</th>\n",
       "      <th>0.17</th>\n",
       "      <th>0.18</th>\n",
       "      <th>0.19</th>\n",
       "      <th>0.20</th>\n",
       "      <th>0.21</th>\n",
       "      <th>0.22</th>\n",
       "      <th>0.23</th>\n",
       "      <th>0.24</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.26</th>\n",
       "      <th>0.27</th>\n",
       "      <th>0.28</th>\n",
       "      <th>0.29</th>\n",
       "      <th>0.30</th>\n",
       "      <th>0.31</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.34</th>\n",
       "      <th>0.35</th>\n",
       "      <th>0.36</th>\n",
       "      <th>0.37</th>\n",
       "      <th>0.38</th>\n",
       "      <th>...</th>\n",
       "      <th>0.578</th>\n",
       "      <th>0.579</th>\n",
       "      <th>0.580</th>\n",
       "      <th>0.581</th>\n",
       "      <th>0.582</th>\n",
       "      <th>0.583</th>\n",
       "      <th>0.584</th>\n",
       "      <th>0.585</th>\n",
       "      <th>0.586</th>\n",
       "      <th>0.587</th>\n",
       "      <th>0.588</th>\n",
       "      <th>0.589</th>\n",
       "      <th>0.590</th>\n",
       "      <th>0.591</th>\n",
       "      <th>0.592</th>\n",
       "      <th>0.593</th>\n",
       "      <th>0.594</th>\n",
       "      <th>0.595</th>\n",
       "      <th>0.596</th>\n",
       "      <th>0.597</th>\n",
       "      <th>0.598</th>\n",
       "      <th>0.599</th>\n",
       "      <th>0.600</th>\n",
       "      <th>0.601</th>\n",
       "      <th>0.602</th>\n",
       "      <th>0.603</th>\n",
       "      <th>0.604</th>\n",
       "      <th>0.605</th>\n",
       "      <th>0.606</th>\n",
       "      <th>0.607</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  0  0.1  0.2  0.3  0.4  ...  0.612  0.613  0.614  0.615  0.616  0.617\n",
       "0  4  0    0    0    0    0  ...      0      0      0      0      0      0\n",
       "1  3  0    0    0    0    0  ...      0      0      0      0      0      0\n",
       "2  0  0    0    0    0    0  ...      0      0      0      0      0      0\n",
       "3  2  0    0    0    0    0  ...      0      0      0      0      0      0\n",
       "4  8  0    0    0    0    0  ...      0      0      0      0      0      0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['5'],axis=1).astype(np.float32).to_numpy()\n",
    "y=data['5'].astype(np.float32).to_numpy()\n",
    "y=to_categorical(data['5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors shape:  (2000, 784)\n",
      "Target shape:  (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictors shape: \",X.shape)\n",
    "print(\"Target shape: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 4s 21ms/step - loss: 21.8260 - accuracy: 0.3700 - val_loss: 6.8355 - val_accuracy: 0.5367\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 4.0669 - accuracy: 0.6529 - val_loss: 4.4896 - val_accuracy: 0.6133\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 2.0650 - accuracy: 0.7593 - val_loss: 3.6885 - val_accuracy: 0.6700\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 1.3050 - accuracy: 0.8143 - val_loss: 3.5145 - val_accuracy: 0.6600\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.8603 - accuracy: 0.8471 - val_loss: 3.0664 - val_accuracy: 0.7317\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.5377 - accuracy: 0.8814 - val_loss: 3.2891 - val_accuracy: 0.7267\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.9150 - val_loss: 3.0680 - val_accuracy: 0.7317\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.2568 - accuracy: 0.9321 - val_loss: 2.9857 - val_accuracy: 0.7483\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1409 - accuracy: 0.9557 - val_loss: 3.0039 - val_accuracy: 0.7483\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9707 - val_loss: 2.7473 - val_accuracy: 0.7650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d626fc8d08>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50,activation='relu',input_shape=(784,)))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y,validation_split=0.3,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You should see better than 90% accuracy recognizing handwritten digits, even while using a small training set of only 2000 images!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60062bfbbdb55d7c70b884c78dba17d93f7bddb21846b67229a99cf865725014"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
