{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Random Forests\n",
    "\n",
    "Bagging is an ensemble method involving training the same algorithm many times using different subsets sampled from the training data. In this chapter, you'll understand how bagging can be used to create a tree ensemble. You'll also learn how the random forests algorithm can lead to further ensemble diversity through randomization at the level of each split in the trees forming the ensemble.\n",
    "\n",
    "## Define the bagging classifier\n",
    "\n",
    "In the following exercises you'll work with the Indian Liver Patient dataset from the UCI machine learning repository. Your task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. You'll do so using a Bagging Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=pd.read_csv(\"indian_liver_patient_preprocessed.csv\",index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "#data.Gender=data.Gender.map({'Male':1,'Female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.Dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "X=data.drop('Liver_disease', axis=1)\n",
    "y=data['Liver_disease']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20, stratify=y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.692113</td>\n",
       "      <td>-0.356035</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.457635</td>\n",
       "      <td>-0.279340</td>\n",
       "      <td>-0.236238</td>\n",
       "      <td>0.385998</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>0.792118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>-1.529043</td>\n",
       "      <td>-0.436391</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.367231</td>\n",
       "      <td>-0.377687</td>\n",
       "      <td>-0.336376</td>\n",
       "      <td>-0.352211</td>\n",
       "      <td>-0.174507</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-0.171670</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.424343</td>\n",
       "      <td>-0.564476</td>\n",
       "      <td>-0.235630</td>\n",
       "      <td>-0.308752</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.959354</td>\n",
       "      <td>1.105288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-1.960935</td>\n",
       "      <td>-0.291751</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>1.165532</td>\n",
       "      <td>-0.284804</td>\n",
       "      <td>-0.298393</td>\n",
       "      <td>1.308759</td>\n",
       "      <td>0.959354</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-0.480164</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.474072</td>\n",
       "      <td>-0.290267</td>\n",
       "      <td>-0.263863</td>\n",
       "      <td>-0.813592</td>\n",
       "      <td>-0.678445</td>\n",
       "      <td>-0.460559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "150  0.692113            -0.356035             -0.353271   \n",
       "377 -1.529043            -0.436391             -0.459878   \n",
       "473 -0.171670            -0.372106             -0.424343   \n",
       "285 -1.960935            -0.291751             -0.353271   \n",
       "358 -0.480164            -0.420320             -0.459878   \n",
       "\n",
       "     Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "150                 -0.457635                     -0.279340   \n",
       "377                 -0.367231                     -0.377687   \n",
       "473                 -0.564476                     -0.235630   \n",
       "285                  1.165532                     -0.284804   \n",
       "358                 -0.474072                     -0.290267   \n",
       "\n",
       "     Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "150                       -0.236238            0.385998     0.833369   \n",
       "377                       -0.336376           -0.352211    -0.174507   \n",
       "473                       -0.308752            0.293722     0.959354   \n",
       "285                       -0.298393            1.308759     0.959354   \n",
       "358                       -0.263863           -0.813592    -0.678445   \n",
       "\n",
       "     Albumin_and_Globulin_Ratio_std  Is_male_std  \n",
       "150                        0.792118            1  \n",
       "377                       -0.147390            0  \n",
       "473                        1.105288            1  \n",
       "285                       -0.147390            1  \n",
       "358                       -0.460559            1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=100, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, you'll train bc and evaluate its test set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "print('Test set accuracy of bc: {:.2f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 1 decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of dt: 0.63\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "acc_test_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print('Test set accuracy of dt: {:.2f}'.format(acc_test_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of Bag Evaluation\n",
    "\n",
    "Recall that in bagging, some instances may be sampled several times for one model. On the other hand, other instance may not be sampled at all.\n",
    "\n",
    "On average, for each model, 63% of the training instances are sampled. The remaining 37% that are not sampled constitute what is known as the Out-of-bag or OOB instances. Since OOB instances are not seen by a model during training, these can be used to estimate the performance of the ensemble without the need for cross-validation. This technique is known as OOB-evaluation.\n",
    "\n",
    "Note that in scikit-learn, the OOB-score corresponds to the accuracy for classifiers and the r-squared score for regressors. Now fit bc to the training set and predict the test set labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the ground\n",
    "\n",
    "In the following exercises, you'll compare the OOB accuracy to the test set accuracy of a bagging classifier trained on the Indian Liver Patient dataset.\n",
    "\n",
    "In sklearn, you can evaluate the OOB accuracy of an ensemble classifier by setting the parameter oob_score to True during instantiation. After training the classifier, the OOB accuracy can be obtained by accessing the .oob_score_ attribute from the corresponding instance.\n",
    "\n",
    "In your environment, we have made available the class DecisionTreeClassifier from sklearn.tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, you'll train bc and compare its test set accuracy to its OOB accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB Score vs Test Set Score\n",
    "\n",
    "Now that you instantiated bc, you will fit it to the training set and evaluate its test set and OOB accuracies.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The feature matrices X_train and X_test, as well as the arrays of labels y_train and y_test are available in your workspace. In addition, we have also loaded the classifier bc instantiated in the previous exercise and the function accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.698, OOB accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set accuracy and the OOB accuracy of bc are both roughly equal to 70%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests (RF)\n",
    "\n",
    "In Bagging, the base estimator can be anything, including Decision Tree, Logistic Regression, Neural Net,....\n",
    "\n",
    "$d=\\sqrt num~of~features$\n",
    "\n",
    "**Feature Importance**\n",
    "\n",
    "When a tree based method is trained, the predictive power of a feature or its importance can be assessed. In scikit-learn, feature importance is assessed by measuring how much the tree nodes use a particular feature to reduce impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0   0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1   1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2   2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3   3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4   4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "\n",
       "   Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                       1                    0      0  \n",
       "1                       1                    0      0  \n",
       "2                       1                    0      0  \n",
       "3                       1                    0      0  \n",
       "4                       1                    0      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike=pd.read_csv(\"bikes.csv\")\n",
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'cnt',\n",
       "       'instant', 'mnth', 'yr', 'Clear to partly cloudy',\n",
       "       'Light Precipitation', 'Misty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'cnt',\n",
    "       'instant', 'mnth', 'yr', 'Clear to partly cloudy',\n",
    "       'Light Precipitation', 'Misty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike['cnt'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bike.drop('cnt',axis='columns')\n",
    "y=bike['cnt']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an RF regressor\n",
    "\n",
    "In the following exercises you'll predict bike rental demand in the Capital Bikeshare program in Washington, D.C using historical weather data from the Bike Sharing Demand dataset available through Kaggle. For this purpose, you will be using the random forests algorithm. As a first step, you'll define a random forests regressor and fit it to the training set.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_train and the array y_train are available in your workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Import RandomForestRegressor from sklearn.ensemble.\n",
    "\n",
    "* Instantiate a RandomForestRegressor called rf consisting of 25 trees.\n",
    "\n",
    "* Fit rf to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the test set RMSE evaluation part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the RF regressor\n",
    "\n",
    "You'll now evaluate the test set RMSE of the random forests regressor rf that you trained in the previous exercise.\n",
    "\n",
    "The dataset is processed for you and split into 80% train and 20% test. The features matrix X_test, as well as the array y_test are available in your workspace. In addition, we have also loaded the model rf that you trained in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 51.84\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = (MSE(y_test,y_pred))**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try training a single CART on the same dataset. The test set RMSE achieved by rf is significantly smaller than that achieved by a single CART!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing features importances\n",
    "\n",
    "In this exercise, you'll determine which features were the most predictive according to the random forests regressor rf that you trained in a previous exercise.\n",
    "\n",
    "For this purpose, you'll draw a horizontal barplot of the feature importance as assessed by rf. Fortunately, this can be done easily thanks to plotting capabilities of pandas.\n",
    "\n",
    "We have created a pandas.Series object called importances containing the feature names as index and their importances as values. In addition, matplotlib.pyplot is available as plt and pandas as pd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Call the .sort_values() method on importances and assign the result to importances_sorted.\n",
    "\n",
    "* Call the .plot() method on importances_sorted and set the arguments:\n",
    "\n",
    "    * kind to 'barh'\n",
    "    * color to 'lightgreen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen')\n",
    "plt.title('Features Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, hr and workingday are the most important features according to rf. The importances of these two features add up to more than 90%!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60062bfbbdb55d7c70b884c78dba17d93f7bddb21846b67229a99cf865725014"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
